

## 1.**å¾®è°ƒåœ¨ImageNetä¸Šé¢„è®­ç»ƒå¥½çš„Resnet18**

**é—®GPTçš„promptï¼šåœ¨imageNetä¸Šé¢„è®­ç»ƒå¥½çš„Resnet18æ¨¡å‹ï¼Œå¦‚ä½•åªæ›´æ”¹æœ€åçš„å…¨è¿æ¥å±‚ç¥ç»å…ƒä¸ªæ•°å¹¶åªå¾®è°ƒæ›´æ”¹åçš„è¿™å‡ å±‚å…¨è¿æ¥å±‚çš„å‚æ•°å‘¢ï¼Ÿ**

------

è¦åœ¨ ImageNet ä¸Šé¢„è®­ç»ƒçš„ ResNet18 æ¨¡å‹ä¸Š **åªæ›´æ”¹æœ€åçš„å…¨è¿æ¥å±‚ï¼ˆ`fc` å±‚ï¼‰çš„ç¥ç»å…ƒä¸ªæ•°**ï¼Œå¹¶ **åªå¾®è°ƒï¼ˆfine-tuneï¼‰è¿™ä¸ªæ–°åŠ çš„å±‚**ï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š

------

### âœ… 1. åŠ è½½é¢„è®­ç»ƒçš„ ResNet18 æ¨¡å‹

```python
import torch
import torch.nn as nn
from torchvision import models

# åŠ è½½ ImageNet ä¸Šé¢„è®­ç»ƒçš„ ResNet18
model = models.resnet18(pretrained=True)
```

### âœ… 2. æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚ï¼ˆ`fc`ï¼‰

å‡è®¾ä½ è¦æ”¹æˆè¾“å‡ºç±»åˆ«æ•°ä¸º `num_classes`ï¼š

```python
num_classes = 10  # æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ç±»åˆ«æ•°
model.fc = nn.Linear(model.fc.in_features, num_classes)
```



### âœ… 3. å†»ç»“é™¤æœ€åä¸€å±‚ä»¥å¤–çš„æ‰€æœ‰å‚æ•°ï¼ˆåªè®­ç»ƒ fcï¼‰

```python
for param in model.parameters():
    param.requires_grad = False  # å†»ç»“æ‰€æœ‰å‚æ•°

for param in model.fc.parameters():
    param.requires_grad = True   # åªè®­ç»ƒæ–°çš„å…¨è¿æ¥å±‚

```



âœ… 4. ä¼˜åŒ–å™¨ä¸­åªä¼ å…¥å¯è®­ç»ƒå‚æ•°

```python
optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)
```

### âœ… 5. æ­£å¸¸è®­ç»ƒ

ç»§ç»­ç¼–å†™ lossã€forwardã€backwardã€step çš„è®­ç»ƒæµç¨‹å³å¯ã€‚ä½ åªä¼šè®­ç»ƒæ–°åŠ çš„æœ€åä¸€å±‚ã€‚

![1746024315624](./1746024315624.jpg)







ä¸‹é¢æ˜¯ä¸€ä¸ª**å®Œæ•´çš„è®­ç»ƒè„šæœ¬æ¨¡æ¿**ï¼Œç”¨äºåŠ è½½ ImageNet ä¸Šé¢„è®­ç»ƒçš„ ResNet18ï¼Œ**æ›¿æ¢æœ€åä¸€å±‚ä¸ºè‡ªå®šä¹‰è¾“å‡ºç±»åˆ«æ•°çš„æ–°å…¨è¿æ¥å±‚ï¼Œå¹¶åªå¾®è°ƒè¿™ä¸€å±‚**ï¼š

âœ… å®Œæ•´è®­ç»ƒè„šæœ¬ï¼ˆåªå¾®è°ƒæœ€åä¸€å±‚ï¼‰

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models

# === å‚æ•°è®¾ç½® ===
num_classes = 10  # ä½ çš„ç±»åˆ«æ•°
batch_size = 32
learning_rate = 0.001
num_epochs = 5
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === æ•°æ®é¢„å¤„ç† ===
transform = transforms.Compose([
    transforms.Resize(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# === åŠ è½½æ•°æ®é›†ï¼ˆä»¥ImageFolderä¸ºä¾‹ï¼‰===
train_dataset = datasets.ImageFolder(root='your_train_data_path', transform=transform)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# === åŠ è½½é¢„è®­ç»ƒçš„ ResNet18 ===
model = models.resnet18(pretrained=True)

# === æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚ï¼ˆfcï¼‰ ===
model.fc = nn.Linear(model.fc.in_features, num_classes)

# === å†»ç»“é™¤æœ€åä¸€å±‚ä»¥å¤–çš„æ‰€æœ‰å‚æ•° ===
for param in model.parameters():
    param.requires_grad = False

# === è§£å†»æœ€åä¸€å±‚ï¼ˆfcï¼‰å‚æ•° ===
for param in model.fc.parameters():
    param.requires_grad = True

# === æ”¾å…¥è®¾å¤‡ï¼ˆGPU / CPUï¼‰===
model = model.to(device)

# === å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼ˆåªä¼˜åŒ– fc å±‚ï¼‰===
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.fc.parameters(), lr=learning_rate, momentum=0.9)

# === å¼€å§‹è®­ç»ƒ ===
model.train()
for epoch in range(num_epochs):
    running_loss = 0.0
    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
    
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}")

print("Finished Training!")

```

`your_train_data_path` æ¢æˆä½ è‡ªå·±çš„æ•°æ®é›†è·¯å¾„ï¼ˆä½¿ç”¨çš„æ˜¯ `ImageFolder` æ ¼å¼ï¼‰ã€‚

å¦‚æœä½ ä¹Ÿæƒ³åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°ç²¾åº¦ï¼Œæˆ‘å¯ä»¥å¸®ä½ åŠ éªŒè¯éƒ¨åˆ†ã€‚

è‹¥ä½ å°†æ¥å¸Œæœ›å¾®è°ƒæ›´å¤šå±‚ï¼Œåªéœ€è®¾ç½®æ›´å¤šå±‚çš„ `requires_grad=True`ã€‚



å¥½çš„ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ª**åŒ…å«è®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹çš„å®Œæ•´ PyTorch å¾®è°ƒè„šæœ¬**ï¼Œé€‚ç”¨äº**åªå¾®è°ƒ ImageNet ä¸Šé¢„è®­ç»ƒçš„ ResNet18 æœ€åä¸€å±‚**ï¼ŒåŒæ—¶åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°ç²¾åº¦ã€‚

âœ… å®Œæ•´è®­ç»ƒ+éªŒè¯è„šæœ¬ï¼ˆåªå¾®è°ƒ ResNet18 æœ€åä¸€å±‚ï¼‰

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import time

# === å‚æ•°è®¾ç½® ===
num_classes = 10  # ä½ çš„ç›®æ ‡ç±»åˆ«æ•°
batch_size = 32
learning_rate = 0.001
num_epochs = 10
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === æ•°æ®é¢„å¤„ç† ===
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# === åŠ è½½è®­ç»ƒå’ŒéªŒè¯é›† ===
train_dataset = datasets.ImageFolder(root='your_train_data_path', transform=transform)
val_dataset = datasets.ImageFolder(root='your_val_data_path', transform=transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# === åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¹¶æ›¿æ¢å…¨è¿æ¥å±‚ ===
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, num_classes)

# === å†»ç»“å…¶ä»–å±‚ï¼Œåªè®­ç»ƒæœ€åä¸€å±‚ ===
for param in model.parameters():
    param.requires_grad = False
for param in model.fc.parameters():
    param.requires_grad = True

model = model.to(device)

# === å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ ===
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.fc.parameters(), lr=learning_rate, momentum=0.9)

# === è®­ç»ƒå’ŒéªŒè¯å¾ªç¯ ===
for epoch in range(num_epochs):
    start_time = time.time()
    
    # === Training ===
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    train_loss = running_loss / len(train_loader)
    train_acc = correct / total

    # === Validation ===
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    val_loss = val_loss / len(val_loader)
    val_acc = correct / total

    elapsed = time.time() - start_time
    print(f"Epoch [{epoch+1}/{num_epochs}] - "
          f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, "
          f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, "
          f"Time: {elapsed:.2f}s")

print("Training complete!")

```

### ğŸ“ ä½ éœ€è¦å‡†å¤‡ï¼š

- `your_train_data_path`: æŒ‡å‘è®­ç»ƒé›†æ–‡ä»¶å¤¹ï¼ˆå­æ–‡ä»¶å¤¹åä¸ºç±»åˆ«åï¼‰
- `your_val_data_path`: æŒ‡å‘éªŒè¯é›†æ–‡ä»¶å¤¹ï¼ˆç»“æ„åŒä¸Šï¼‰





å¦‚æœä½ æƒ³è¦å¾®è°ƒ **ResNet18 çš„æœ€åè¾“å‡ºä¸º 512 é€šé“çš„éƒ¨åˆ†ï¼ˆå³æœ€åçš„ `layer4` æ¨¡å—ï¼‰** å’Œ **æ›´æ”¹åçš„å…¨è¿æ¥å±‚**ï¼Œä½ åªéœ€è¦ï¼š

------

### âœ… æ­¥éª¤æ€»ç»“ï¼š

1. **åŠ è½½é¢„è®­ç»ƒçš„ ResNet18**
2. **ä¿®æ”¹æœ€åçš„å…¨è¿æ¥å±‚**ï¼ˆå¦‚ï¼š`fc = nn.Linear(512, num_classes)`ï¼‰
3. **åªè§£å†» layer4 å’Œ fc çš„å‚æ•°ï¼Œå…¶ä½™éƒ¨åˆ†å†»ç»“**

------

### ğŸ”§ å®ç°ä»£ç ï¼ˆåªå¾®è°ƒ `layer4` å’Œ `fc`ï¼‰ï¼š

```python
import torch
import torch.nn as nn
from torchvision import models

num_classes = 10  # æ ¹æ®ä»»åŠ¡ä¿®æ”¹
model = models.resnet18(pretrained=True)

# === ä¿®æ”¹æœ€åå…¨è¿æ¥å±‚ ===
model.fc = nn.Linear(model.fc.in_features, num_classes)

# === å†»ç»“æ‰€æœ‰å±‚ ===
for param in model.parameters():
    param.requires_grad = False

# === è§£å†» layer4ï¼ˆè¾“å‡ºé€šé“ä¸º 512ï¼‰ å’Œ fc å±‚ ===
for param in model.layer4.parameters():
    param.requires_grad = True
for param in model.fc.parameters():
    param.requires_grad = True

# === æŠŠæ¨¡å‹ç§»åˆ°GPU ===
model = model.to('cuda' if torch.cuda.is_available() else 'cpu')

# === è®¾ç½®ä¼˜åŒ–å™¨ï¼Œåªæ›´æ–° layer4 å’Œ fc çš„å‚æ•° ===
optimizer = torch.optim.SGD(
    list(model.layer4.parameters()) + list(model.fc.parameters()),
    lr=0.001, momentum=0.9, weight_decay=1e-4
)

```

### ğŸ§  è¡¥å……è¯´æ˜ï¼š

- `model.layer4` æ˜¯ ResNet18 çš„æœ€åä¸€ä¸ªæ®‹å·® blockï¼Œè¾“å‡ºé€šé“æ­£æ˜¯ 512ã€‚
- è¿™æ ·åšçš„å¥½å¤„æ˜¯ä¿ç•™äº†åº•å±‚é€šç”¨ç‰¹å¾ï¼ŒåŒæ—¶å…è®¸ä½ ç»†è°ƒä»»åŠ¡ç›¸å…³çš„é«˜å±‚è¯­ä¹‰ç‰¹å¾ã€‚
- å¦‚æœä½ æœªæ¥è¦â€œç»§ç»­è§£å†» layer3â€ï¼Œå¯ä»¥è¿½åŠ ç±»ä¼¼ï¼š

```python
for param in model.layer3.parameters():
    param.requires_grad = True

```



å¥½çš„ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ª**å®Œæ•´çš„è®­ç»ƒéªŒè¯è„šæœ¬**ï¼Œä»¥ `ImageNet` ä¸Šé¢„è®­ç»ƒçš„ `ResNet18` ä¸ºåŸºç¡€ï¼Œä»…**å¾®è°ƒæœ€åçš„ `layer4` å’Œæ›´æ¢åçš„ `fc` å±‚**ã€‚

------

### âœ… å¾®è°ƒ `ResNet18`ï¼ˆä»… `layer4` å’Œ `fc`ï¼‰çš„å®Œæ•´ PyTorch ç¤ºä¾‹ï¼š

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader

# === å‚æ•° ===
num_classes = 10  # æ ¹æ®ä½ çš„ä»»åŠ¡ä¿®æ”¹
batch_size = 32
learning_rate = 0.001
num_epochs = 10

# === æ•°æ®é¢„å¤„ç† ===
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# === æ•°æ®é›†è·¯å¾„ï¼ˆä½ éœ€è¦æ›¿æ¢æˆè‡ªå·±çš„ï¼‰ ===
train_dataset = datasets.ImageFolder("path/to/train", transform=transform_train)
val_dataset = datasets.ImageFolder("path/to/val", transform=transform_val)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)

# === åŠ è½½ ResNet18 æ¨¡å‹å¹¶ä¿®æ”¹ fc å±‚ ===
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, num_classes)

# === å†»ç»“æ‰€æœ‰å‚æ•° ===
for param in model.parameters():
    param.requires_grad = False

# === è§£å†» layer4 å’Œ fc å±‚ ===
for param in model.layer4.parameters():
    param.requires_grad = True
for param in model.fc.parameters():
    param.requires_grad = True

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# === ä¼˜åŒ–å™¨ä»…æ›´æ–° layer4 å’Œ fc å‚æ•° ===
optimizer = optim.SGD(
    list(model.layer4.parameters()) + list(model.fc.parameters()),
    lr=learning_rate, momentum=0.9, weight_decay=1e-4
)

# === æŸå¤±å‡½æ•° ===
criterion = nn.CrossEntropyLoss()

# === è®­ç»ƒä¸éªŒè¯ ===
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    train_loss = running_loss / total
    train_acc = correct / total

    # === éªŒè¯ ===
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    val_loss /= total
    val_acc = correct / total

    print(f"Epoch [{epoch+1}/{num_epochs}] "
          f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, "
          f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

```

### âœ… åŠŸèƒ½å›é¡¾ï¼š

- ä½¿ç”¨ `ImageFolder` åŠ è½½æ•°æ®ï¼ˆä½ éœ€å‡†å¤‡è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼‰ã€‚
- ä»…å¾®è°ƒ `layer4` å’Œ `fc`ï¼Œå…¶ä»–å‚æ•°å†»ç»“ã€‚
- ä¼˜åŒ–å™¨åªæ›´æ–°éœ€è¦è®­ç»ƒçš„éƒ¨åˆ†ã€‚
- ç®€æ´çš„è®­ç»ƒ + éªŒè¯è¿‡ç¨‹ã€‚





å¥½çš„ï¼Œä¸‹é¢æ˜¯**å®Œæ•´çš„è®­ç»ƒè„šæœ¬ï¼ˆæ”¯æŒ TensorBoard å¯è§†åŒ– + ä¿å­˜éªŒè¯é›†å‡†ç¡®ç‡æœ€é«˜çš„æ¨¡å‹ï¼‰**ï¼Œåœ¨ä¹‹å‰åŸºç¡€ä¸Šæ·»åŠ äº†ä»¥ä¸‹åŠŸèƒ½ï¼š

### âœ… æ–°å¢åŠŸèƒ½ï¼š

- ä½¿ç”¨ `torch.utils.tensorboard.SummaryWriter` å®æ—¶è®°å½•æŸå¤±å’Œå‡†ç¡®ç‡ï¼›
- ä¿å­˜éªŒè¯é›†å‡†ç¡®ç‡æœ€é«˜çš„æ¨¡å‹åˆ°æŒ‡å®šè·¯å¾„ï¼›
- æ—¥å¿—è¾“å‡ºæ›´æ¸…æ™°ã€‚

------

### âœ… å®Œæ•´ä»£ç ï¼ˆå« TensorBoard + ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼‰ï¼š



```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import os

# === å‚æ•° ===
num_classes = 10
batch_size = 32
learning_rate = 0.001
num_epochs = 10
save_path = "best_model.pth"
log_dir = "runs/resnet18_finetune"

# === TensorBoard è®°å½•å™¨ ===
writer = SummaryWriter(log_dir=log_dir)

# === æ•°æ®é¢„å¤„ç† ===
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])
transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# === åŠ è½½æ•°æ®é›† ===
train_dataset = datasets.ImageFolder("path/to/train", transform=transform_train)
val_dataset = datasets.ImageFolder("path/to/val", transform=transform_val)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)

# === æ¨¡å‹åŠ è½½ä¸å‚æ•°è®¾ç½® ===
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, num_classes)

# å†»ç»“æ‰€æœ‰å‚æ•°
for param in model.parameters():
    param.requires_grad = False
# ä»…è®­ç»ƒ layer4 å’Œ fc
for param in model.layer4.parameters():
    param.requires_grad = True
for param in model.fc.parameters():
    param.requires_grad = True

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

optimizer = optim.SGD(
    list(model.layer4.parameters()) + list(model.fc.parameters()),
    lr=learning_rate, momentum=0.9, weight_decay=1e-4
)
criterion = nn.CrossEntropyLoss()

# === è®­ç»ƒä¸éªŒè¯ ===
best_val_acc = 0.0
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    train_loss = running_loss / total
    train_acc = correct / total

    # === éªŒè¯ ===
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    val_loss /= total
    val_acc = correct / total

    # === å†™å…¥ TensorBoard ===
    writer.add_scalar("Loss/Train", train_loss, epoch)
    writer.add_scalar("Loss/Val", val_loss, epoch)
    writer.add_scalar("Accuracy/Train", train_acc, epoch)
    writer.add_scalar("Accuracy/Val", val_acc, epoch)

    print(f"[Epoch {epoch+1}/{num_epochs}] "
          f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | "
          f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

    # === ä¿å­˜æœ€ä¼˜æ¨¡å‹ ===
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), save_path)
        print(f"âœ… Saved best model with val acc: {val_acc:.4f}")

writer.close()

```

### ğŸ“Œ ä½¿ç”¨æ–¹æ³•æé†’ï¼š

1. æ›¿æ¢ `"path/to/train"` å’Œ `"path/to/val"` ä¸ºä½ çš„æ•°æ®é›†è·¯å¾„ï¼›
2. å¦‚æœä½ ç”¨çš„æ˜¯ `.py` è„šæœ¬ï¼Œè¿è¡Œåä½¿ç”¨å‘½ä»¤æ‰“å¼€ TensorBoardï¼š

```python
tensorboard --logdir=runs/resnet18_finetune

```

   3.è¾“å‡ºæ¨¡å‹ä¿å­˜åœ¨å½“å‰ç›®å½•çš„ `best_model.pth` æ–‡ä»¶ä¸­ã€‚





ä¸‹é¢æ˜¯ä½ è¦æ±‚çš„ **æ¨ç†æµ‹è¯•è„šæœ¬ï¼ˆé’ˆå¯¹æ•´ä¸ªæ–‡ä»¶å¤¹ï¼‰**ï¼ŒåŠŸèƒ½å¦‚ä¸‹ï¼š

------

### âœ… åŠŸèƒ½æ¦‚è¿°ï¼š

- åŠ è½½è®­ç»ƒå¥½çš„ ResNet-18 å¾®è°ƒæ¨¡å‹ï¼›

- å¯¹æµ‹è¯•é›†ä¸­æ¯å¼ å›¾ç‰‡è¿›è¡Œé¢„æµ‹ï¼›

- è¾“å‡ºé¢„æµ‹æ ‡ç­¾ä¸çœŸå®æ ‡ç­¾ï¼›

- è®¡ç®—å¹¶ **ä¿å­˜æœ€ç»ˆ Top-1 åˆ†ç±»å‡†ç¡®ç‡**ï¼›

- æ”¯æŒ GPUï¼Œè‡ªåŠ¨é€‚é…ã€‚

  âœ… æ¨ç†ä»£ç ï¼ˆæµ‹è¯•æ•´ä¸ªæ–‡ä»¶å¤¹ + ä¿å­˜ Top-1 å‡†ç¡®ç‡ï¼‰

  ```python
  import torch
  from torchvision import models, transforms, datasets
  from torch.utils.data import DataLoader
  import os
  
  # === å‚æ•°è®¾ç½® ===
  model_path = "best_model.pth"
  test_dir = "path/to/test"  # æµ‹è¯•é›†æ–‡ä»¶å¤¹ï¼Œè¦æ±‚ä¸º ImageFolder æ ¼å¼ï¼štest/class_x/*.jpg
  batch_size = 32
  num_classes = 10
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  
  # === ç±»åˆ«åï¼ˆæŒ‰ImageFolderè‡ªåŠ¨æ’åºï¼‰===
  class_names = sorted(os.listdir(test_dir))  # æˆ–æ‰‹åŠ¨æŒ‡å®šç±»åˆ«é¡ºåº
  
  # === æ•°æ®é¢„å¤„ç† ===
  transform = transforms.Compose([
      transforms.Resize((224, 224)),
      transforms.ToTensor(),
      transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
  ])
  
  # === æµ‹è¯•é›†åŠ è½½ ===
  test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)
  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)
  
  # === æ¨¡å‹åŠ è½½ ===
  model = models.resnet18(pretrained=False)
  model.fc = torch.nn.Linear(model.fc.in_features, num_classes)
  model.load_state_dict(torch.load(model_path, map_location=device))
  model = model.to(device)
  model.eval()
  
  # === æ¨ç† + è®¡ç®—å‡†ç¡®ç‡ ===
  correct = 0
  total = 0
  
  with torch.no_grad():
      for images, labels in test_loader:
          images, labels = images.to(device), labels.to(device)
          outputs = model(images)
          _, predicted = outputs.max(1)
          total += labels.size(0)
          correct += predicted.eq(labels).sum().item()
  
  top1_acc = correct / total
  print(f"âœ… Top-1 Accuracy on Test Set: {top1_acc:.4f}")
  
  # === ä¿å­˜å‡†ç¡®ç‡ç»“æœ ===
  with open("test_accuracy.txt", "w") as f:
      f.write(f"Top-1 Accuracy: {top1_acc:.4f}\n")
  
  ```

  

âœ… ç›®å½•è¦æ±‚ï¼ˆImageFolder ç»“æ„ï¼‰ï¼š

```python
path/to/test/
    â”œâ”€â”€ class0/
    â”‚   â”œâ”€â”€ img001.jpg
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ class1/
    â”‚   â”œâ”€â”€ img021.jpg
    â”‚   â””â”€â”€ ...
    â””â”€â”€ ...

```

### ğŸ“Œ è¾“å‡ºç»“æœï¼š

- æ§åˆ¶å°æ‰“å°ï¼šTop-1 Accuracyï¼›
- æ–‡æœ¬æ–‡ä»¶ä¿å­˜ï¼š`test_accuracy.txt`





## 2.å®ç°å¤šåˆ†ç±»ï¼š

![1747049227393](./1747049227393.jpg)

**prompt:**

æ ¹æ®ä»¥ä¸Šæ–‡ä»¶ï¼Œè¯·å¸®æˆ‘å®ç°ï¼š

â‘ åˆ†ç±»ç½‘ç»œï¼šæ ¹æ®test_fine-tuning_new.pyæ–‡ä»¶å¾®è°ƒæœ€ålayer4å’Œå…¨è¿æ¥å±‚çš„ç½‘ç»œä½œä¸ºTeacherç½‘ç»œï¼Œå…¶å¯¹åº”å¾®è°ƒçš„å‚æ•°å·²ç»ä¿å­˜åœ¨D:\Projects\DeSTSeg\destseg++\eval-master\all_classify_eval-master\logs\fine_tuning\fold_9_best.pthä¸­ï¼Œè®©å¾®è°ƒè¿‡åçš„è¿™ä¸ªæ•´ä¸ªresnetç½‘ç»œä½œä¸ºåˆ†ç±»ç½‘ç»œæ¥å®ç°åˆ¤æ–­æ¯ä¸ªå›¾åƒæ‰€å±ç±»åˆ«ï¼ˆæˆ–æ¯ä¸ªbatchå›¾åƒæ‰€å±ç±»åˆ«ï¼‰ã€‚æ•™å¸ˆç½‘ç»œï¼šæ•™å¸ˆç½‘ç»œTeacherNetç»§ç»­ä½¿ç”¨timmåˆ›å»ºçš„ResNetæ¥å¯¹å­¦ç”Ÿç½‘ç»œå®ç°è’¸é¦ã€‚ï¼ˆå…¶ä¸­ï¼šåˆ©ç”¨layer1åˆ°layer3å®ç°å¯¹å­¦ç”Ÿç½‘ç»œçš„è’¸é¦ï¼‰  æ³¨æ„ï¼šæ­¤å¤„çš„åˆ†ç±»ç½‘ç»œæ˜¯å·²ç»å¾®è°ƒå¥½çš„ï¼Œæ•™å¸ˆç½‘ç»œæ˜¯ç›´æ¥åŠ è½½timmåˆ›å»ºçš„ResNetå‚æ•°ï¼Œè¿™æ˜¯ä¸¤ä¸ªä¸åŒçš„resnetç½‘ç»œæ¨¡å‹

â‘¡å°†å­¦ç”Ÿç½‘ç»œæ¨¡å‹çš„encoderéƒ¨åˆ†è®¾ç½®ä¸ºMVTECADçš„15ä¸ªç±»å…¬ç”¨çš„å­¦ç”Ÿç½‘ç»œencoderï¼ˆOCBEéƒ¨åˆ†ä¹Ÿæ˜¯å…±äº«çš„æ¨¡å—ï¼‰ï¼Œdecoderéƒ¨åˆ†å’Œsegmentation_netéƒ¨åˆ†è®¾ç½®ä¸ºæ¯ç±»æ‰€ç‰¹æœ‰çš„éƒ¨åˆ†{å…¶ä¸­ï¼šencoderå®šä¹‰ä¸ºä¸€ä¸ªç±»ï¼Œdecoderå®šä¹‰ä¸ºä¸€ä¸ªç±»ï¼ŒSegmentationNetå®šä¹‰ä¸ºä¸€ä¸ªç±»}

â‘¢è®­ç»ƒé˜¶æ®µï¼šå¯¹äºæ¯ä¸ªobjï¼Œè°ƒç”¨trainå‡½æ•°ï¼Œä¾æ¬¡å¤„ç†æ¯ä¸ªç±»åˆ«ã€‚åœ¨è®­ç»ƒæŸä¸ªç±»åˆ«æ—¶ï¼ŒåŠ è½½å¯¹åº”çš„decoderå’Œseg_netï¼Œä¸å­¦ç”Ÿç½‘ç»œæ¨¡å‹é€šç”¨çš„encoderéƒ¨åˆ†è¿›è¡Œæ‹¼æ¥ï¼Œæ¥å®ç°è’¸é¦è®­ç»ƒã€‚

æµ‹è¯•é˜¶æ®µï¼šåŒç†ï¼Œé¦–å…ˆå°†æµ‹è¯•å›¾åƒè¾“å…¥teacherç½‘ç»œï¼Œæ ¹æ®teacherç½‘ç»œåˆ¤æ–­å‡ºæ˜¯å“ªä¸€ç±»åˆ«ï¼Œç„¶ååŠ è½½å¯¹åº”ç±»åˆ«è®­ç»ƒå¥½çš„decoderéƒ¨åˆ†å’Œsegmentation_netéƒ¨åˆ†ï¼›ç„¶åå†å®ç°å°†æµ‹è¯•å›¾åƒè¾“å…¥å­¦ç”Ÿç½‘ç»œï¼Œå®ç°æœ€ç»ˆç»“æœçš„è®¡ç®—ã€‚

æ•°æ®é›†æ–‡ä»¶è·¯å¾„åŠæ ¼å¼ï¼šmvtec â€”> bottle,cable,capsule,carpet,grid,hazelnut,leather,metal_nut,pill,screw,tile,toothbrush,transistor,wood,zipperâ€”>ground_truth,test,trainâ€”>

â‘ ä¸éœ€è¦å†»ç»“å…±äº«ç¼–ç å™¨ï¼Œåœ¨è®­ç»ƒæ¯ä¸€ä¸ªç±»åˆ«çš„æ—¶å€™ï¼Œéƒ½åŠ è½½å…±äº«ç¼–ç å™¨çš„æƒé‡å‚æ•°ï¼Œâ‘¡å…±äº«ç¼–ç å™¨çš„å‚æ•°ä¹Ÿéœ€è¦åå‘ä¼ æ’­æ›´æ–°â‘¢åœ¨def trainå‡½æ•°ä¿å­˜æœ€ä½³æ¨¡å‹çš„æ—¶å€™ï¼Œä¹Ÿéœ€è¦ä¿å­˜å…±äº«ç¼–ç å™¨éƒ¨åˆ†çš„å‚æ•°ï¼ˆå…±äº«ç¼–ç å™¨å‚æ•°æ”¾åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ï¼‰ï¼Œå„ä¸ªç±»åˆ«å¯¹åº”çš„è§£ç å™¨å’Œè¯­ä¹‰åˆ†å‰²ç½‘ç»œçš„å‚æ•°æ”¾åœ¨ä¸€ä¸ªå¯¹åº”çš„æ–‡ä»¶å¤¹ä¸­ã€‚â‘£è®­ç»ƒæˆ–è€…æµ‹è¯•é˜¶æ®µï¼šéƒ½éœ€è¦åŠ è½½å…±äº«ç¼–ç å™¨çš„å‚æ•°ï¼Œç„¶åæ ¹æ®å¯¹åº”ç±»åˆ«å†åŠ è½½å¯¹åº”çš„ç±»åˆ«è§£ç å™¨å’Œç±»åˆ«åˆ†å‰²å™¨çš„å‚æ•°

### â‘  åˆ†ç±»ç½‘ç»œå’Œæ•™å¸ˆç½‘ç»œå®ç°

```python
# æ–°å¢åˆ†ç±»ç½‘ç»œï¼ˆéœ€åœ¨æ¨¡å‹å®šä¹‰æ–‡ä»¶ä¸­æ·»åŠ ï¼‰
class ClassNet(nn.Module):
    def __init__(self, pretrained_path):
        super().__init__()
        self.backbone = models.resnet18(pretrained=False)
        self.backbone.fc = nn.Linear(512, 15)  # 15ä¸ªç±»åˆ«
        state_dict = torch.load(pretrained_path, map_location="cuda")
        self.backbone.load_state_dict(state_dict)
        self.backbone.eval()
        
    def forward(self, x):
        with torch.no_grad():
            return self.backbone(x)

# ä¿®æ”¹æ•™å¸ˆç½‘ç»œï¼ˆåŸTeacherNetä¿æŒä¸å˜ï¼Œæ–°å¢ç‰¹å¾æå–æ–¹æ³•ï¼‰
class TeacherNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = timm.create_model(
            "resnet18",
            pretrained=True,
            features_only=True,
            out_indices=[1, 2, 3],  # åªè·å–å‰ä¸‰ä¸ªstageçš„ç‰¹å¾
        )
        for param in self.encoder.parameters():
            param.requires_grad = False

    def forward(self, x):
        self.eval()
        features = self.encoder(x)
        return features  # è¿”å›tupleåŒ…å«ä¸‰ä¸ªå±‚æ¬¡çš„ç‰¹å¾
```



### â‘¡ å­¦ç”Ÿç½‘ç»œç»“æ„è°ƒæ•´

```python
# åœ¨model/destseg_old.pyä¸­ä¿®æ”¹
class SharedEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = timm.create_model(
            "resnet18",
            pretrained=False,
            features_only=True,
            out_indices=[1, 2, 3, 4],
        )
        self.bn = nn.BatchNorm2d(448)  # åŸOCBEæ¨¡å—çš„å®ç°
        # åˆå§‹åŒ–ä»£ç å‚è€ƒåŸStudentNetçš„å®ç°

    def forward(self, x):
        x1, x2, x3, x4 = self.encoder(x)
        x = torch.cat([x1, x2, x3], dim=1)
        x = self.bn(x)
        return x

class DeSTSeg(nn.Module):
    def __init__(self, num_classes=15):
        super().__init__()
        self.shared_encoder = SharedEncoder()
        self.decoders = nn.ModuleList(
            [self._build_decoder() for _ in range(num_classes)]
        )
        self.seg_nets = nn.ModuleList(
            [SegmentationNet() for _ in range(num_classes)]
        )

    def _build_decoder(self):
        # åŸStudentNetçš„decoderå®ç°
        decoder = nn.Sequential(
            make_layer(BasicBlock, 512, 512, 2),
            nn.Upsample(scale_factor=2, mode='bilinear'),
            make_layer(BasicBlock, 512, 256, 2),
            # ... å…¶ä»–å±‚å®šä¹‰
        )
        return decoder

    def forward(self, x, class_idx):
        features = self.shared_encoder(x)
        decoded = self.decoders[class_idx](features)
        output = self.seg_nets[class_idx](decoded)
        return output
```



### â‘¢ è®­ç»ƒæµç¨‹æ”¹é€ 

```python
# ä¿®æ”¹trainå‡½æ•°ï¼ˆæ–‡æ¡£1ï¼‰
def train(args, category, class_idx):
    # åˆå§‹åŒ–æ¨¡å‹
    model = DeSTSeg(num_classes=15).cuda()
    teacher = TeacherNet().cuda()
    class_net = ClassNet("D:/path/to/fold_9_best.pth").cuda()

    # ä»…ä¼˜åŒ–å½“å‰ç±»åˆ«çš„å‚æ•°
    optimizer = torch.optim.SGD([
        {'params': model.shared_encoder.parameters()},
        {'params': model.decoders[class_idx].parameters()},
        {'params': model.seg_nets[class_idx].parameters()}
    ], lr=0.001)

    # åŠ è½½å½“å‰ç±»åˆ«æ•°æ®ï¼ˆéœ€ä¿®æ”¹MVTecDatasetï¼‰
    dataset = MVTecDataset(
        is_train=True,
        classname=category,
        mvtec_dir=os.path.join(args.mvtec_path, category, "train/good/"),
        # ...å…¶ä»–å‚æ•°
    )
    
    for batch in DataLoader(dataset, batch_size=32):
        img_aug = batch["img_aug"].cuda()
        img_origin = batch["img_origin"].cuda()

        # æ•™å¸ˆç½‘ç»œè’¸é¦
        with torch.no_grad():
            teacher_features = teacher(img_aug)

        # å­¦ç”Ÿç½‘ç»œå‰å‘
        student_features = model.shared_encoder(img_aug)
        output_segmentation = model.seg_nets[class_idx](
            model.decoders[class_idx](student_features)
        )

        # è®¡ç®—è’¸é¦æŸå¤±
        distillation_loss = sum(
            F.mse_loss(student_features[i], teacher_features[i].detach())
            for i in range(3)
        )
        
        # åŸåˆ†å‰²æŸå¤±è®¡ç®—
        mask = F.interpolate(batch["mask"].cuda(), size=output_segmentation.shape[2:])
        seg_loss = focal_loss(output_segmentation, mask)
        
        total_loss = distillation_loss + seg_loss
        total_loss.backward()
        optimizer.step()
```



### â‘£ æµ‹è¯•æµç¨‹æ”¹é€ 

```python
# ä¿®æ”¹evaluateå‡½æ•°ï¼ˆæ–‡æ¡£3ï¼‰
def evaluate(args, category, model):
    class_net = ClassNet("D:/path/to/fold_9_best.pth").cuda()
    model.eval()
    
    dataset = MVTecDataset(
        is_train=False,
        classname=category,
        mvtec_dir=os.path.join(args.mvtec_path, category, "test/")
    )
    
    for batch in DataLoader(dataset, batch_size=32):
        img = batch["img"].cuda()
        
        # åˆ†ç±»ç½‘ç»œé¢„æµ‹ç±»åˆ«
        with torch.no_grad():
            cls_logits = class_net(img)
            pred_class = torch.argmax(cls_logits, dim=1).item()

        # åŠ è½½å¯¹åº”ç±»åˆ«çš„æ¨¡å—
        output = model(img, pred_class)
        
        # åç»­è¯„ä¼°é€»è¾‘ä¿æŒä¸å˜...
        mask = batch["mask"].cuda()
        # è®¡ç®—metrics...
```

### å…³é”®æ–‡ä»¶ç»“æ„è°ƒæ•´

```
destseg/
â”œâ”€â”€ class_net.py          # åˆ†ç±»ç½‘ç»œå®šä¹‰
â”œâ”€â”€ teacher_net.py        # æ•™å¸ˆç½‘ç»œå®šä¹‰
â”œâ”€â”€ student_net/
â”‚   â”œâ”€â”€ shared_encoder.py # å…±äº«ç¼–ç å™¨
â”‚   â”œâ”€â”€ decoders/         # æ¯ä¸ªç±»åˆ«çš„è§£ç å™¨
â”‚   â””â”€â”€ seg_nets/         # æ¯ä¸ªç±»åˆ«çš„åˆ†å‰²å¤´
â””â”€â”€ train.py              # æ”¹é€ åçš„è®­ç»ƒæµç¨‹
```

### è®­ç»ƒæ‰§è¡Œé€»è¾‘

```python
# ä¸»ç¨‹åºä¿®æ”¹ï¼ˆæ–‡æ¡£1æœ€åéƒ¨åˆ†ï¼‰
if __name__ == "__main__":
    # åˆå§‹åŒ–åˆ†ç±»ç½‘ç»œ
    class_net = ClassNet("D:/path/to/fold_9_best.pth").cuda()
    
    # æŒ‰ç±»åˆ«å¾ªç¯è®­ç»ƒ
    for idx, category in enumerate(ALL_CATEGORY):
        print(f"Training {category} (Class Index: {idx})")
        
        # åˆå§‹åŒ–å­¦ç”Ÿæ¨¡å‹
        model = DeSTSeg(num_classes=15).cuda()
        
        # åŠ è½½å·²æœ‰checkpointï¼ˆå¦‚æœæœ‰ï¼‰
        ckpt_path = f"saved_models/{category}_model.pth"
        if os.path.exists(ckpt_path):
            model.load_state_dict(torch.load(ckpt_path))
            
        # è®­ç»ƒå½“å‰ç±»åˆ«
        train(args, category, class_idx=idx)
        
        # ä¿å­˜å½“å‰ç±»åˆ«å‚æ•°
        torch.save({
            'shared_encoder': model.shared_encoder.state_dict(),
            'decoder': model.decoders[idx].state_dict(),
            'seg_net': model.seg_nets[idx].state_dict()
        }, ckpt_path)
```

### å…³é”®æ”¹è¿›ç‚¹è¯´æ˜

1. **å‚æ•°éš”ç¦»æœºåˆ¶**ï¼š

- ä½¿ç”¨`nn.ModuleList`å®ç°å‚æ•°éš”ç¦»
- æ¯ä¸ªç±»åˆ«çš„decoderå’Œseg_netç‹¬ç«‹ä¿å­˜
- è®­ç»ƒæ—¶é€šè¿‡class_idxåŠ¨æ€é€‰æ‹©æ¨¡å—

1. **å†…å­˜ä¼˜åŒ–**ï¼š

- å…±äº«ç¼–ç å™¨å‚æ•°åœ¨æ‰€æœ‰ç±»åˆ«é—´å¤ç”¨
- æ¯ä¸ªç±»åˆ«è®­ç»ƒæ—¶åªéœ€åŠ è½½å½“å‰ç±»åˆ«çš„ç‰¹å®šå‚æ•°

1. **çµæ´»éƒ¨ç½²**ï¼š

- æµ‹è¯•æ—¶é€šè¿‡åˆ†ç±»ç½‘ç»œè‡ªåŠ¨è·¯ç”±
- æ”¯æŒæŒ‰éœ€åŠ è½½å•ä¸ªç±»åˆ«æ¨¡å‹

1. **å…¼å®¹æ€§ä¿æŒ**ï¼š

- ä¿ç•™åŸæœ‰æŸå¤±å‡½æ•°å’Œè¯„ä¼°æŒ‡æ ‡
- ä»…ä¿®æ”¹æ¨¡å‹ç»“æ„å’Œè®­ç»ƒæµç¨‹

å»ºè®®åœ¨å®é™…ä½¿ç”¨ä¸­é€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿›è¡Œè®­ç»ƒï¼š

```python
# å•ç±»åˆ«è®­ç»ƒç¤ºä¾‹
python train.py --category capsule --class_idx 0
# å…¨ç±»åˆ«é¡ºåºè®­ç»ƒ
python train.py --all_categories
```

























### 1. åˆ†ç±»ç½‘ç»œå®ç°ï¼ˆå¾®è°ƒResNetï¼‰

```python
import timm
import torch
import torch.nn as nn

class FineTunedClassifier(nn.Module):
    def __init__(self, num_classes=15):
        super().__init__()
        self.base_model = timm.create_model("resnet18", pretrained=False)
        self.base_model.fc = nn.Linear(512, num_classes)
        self._load_pretrained("destseg++/eval-master/all_classify_eval-master/logs/fine_tuning/fold_9_best.pth")

    def _load_pretrained(self, ckpt_path):
        state_dict = torch.load(ckpt_path)
        self.load_state_dict(state_dict)
        for param in self.parameters():
            param.requires_grad = False

    def forward(self, x):
        return self.base_model(x)
```



### 2. æ”¹è¿›çš„å­¦ç”Ÿç½‘ç»œç»“æ„

```python
class SharedEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = timm.create_model(
            "resnet18", pretrained=False, features_only=True, out_indices=[1, 2, 3, 4]
        )
        self.bn = nn.BatchNorm2d(448)  # OCBEæ¨¡å—

    def forward(self, x):
        x1, x2, x3, x4 = self.encoder(x)
        return [x1, x2, x3]

class ClassSpecificDecoder(nn.Module):
    def __init__(self, ed=True):
        super().__init__()
        if ed:
            self.decoder_layer4 = make_layer(BasicBlock, 512, 512, 2)
            self.decoder_layer3 = make_layer(BasicBlock, 512, 256, 2)
            self.decoder_layer2 = make_layer(BasicBlock, 256, 128, 2)
            self.decoder_layer1 = make_layer(BasicBlock, 128, 64, 2)

    def forward(self, x_list):
        # ä¸åŸStudentNetç›¸åŒçš„decoderé€»è¾‘
        x = self.bn(x_list)
        b4 = self.decoder_layer4(x)
        b3 = F.interpolate(b4, size=x3.size()[2:], mode="bilinear")
        # ... åç»­decoderæ“ä½œ
        return (b1, b2, b3)

class ClassSpecificSegNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.seg_net = SegmentationNet()
    
    def forward(self, x):
        return self.seg_net(x)
```

### 3. æ”¹è¿›çš„DeSTSegç±»

```python
class EnhancedDeSTSeg(nn.Module):
    def __init__(self, category):
        super().__init__()
        # æ•™å¸ˆç½‘ç»œï¼ˆä¿æŒåŸçŠ¶ï¼‰
        self.teacher_net = TeacherNet()
        
        # å…±äº«ç»„ä»¶
        self.shared_encoder = SharedEncoder()
        
        # ç±»åˆ«ç‰¹å®šç»„ä»¶
        self.decoder = ClassSpecificDecoder()
        self.seg_net = ClassSpecificSegNet()
        
        # åŠ è½½ç±»åˆ«ç‰¹å®šå‚æ•°
        self._load_category_params(category)

    def _load_category_params(self, category):
        # åŠ è½½æŒ‡å®šç±»åˆ«çš„decoderå’Œseg_netå‚æ•°
        ckpt_path = f"saved_models/{category}_params.pth"
        if os.path.exists(ckpt_path):
            params = torch.load(ckpt_path)
            self.decoder.load_state_dict(params['decoder'])
            self.seg_net.load_state_dict(params['seg_net'])

    def forward(self, img_aug, img_origin=None):
        # å…±äº«ç‰¹å¾æå–
        shared_features = self.shared_encoder(img_aug)
        
        # ç±»åˆ«ç‰¹å®šå¤„ç†
        decoder_out = self.decoder(shared_features)
        seg_out = self.seg_net(decoder_out)
        
        # ä¸åŸé€»è¾‘ç›¸åŒçš„åç»­å¤„ç†
        # ...
        return seg_out, de_st_out, de_st_list, contrast
```

### 4. æ”¹è¿›çš„è®­ç»ƒæµç¨‹

```python
def train(args, category):
    # åˆå§‹åŒ–å…±äº«ç»„ä»¶
    shared_encoder = SharedEncoder().cuda()
    
    # åˆå§‹åŒ–ç±»åˆ«ç‰¹å®šç»„ä»¶
    decoder = ClassSpecificDecoder().cuda()
    seg_net = ClassSpecificSegNet().cuda()
    
    # ä¼˜åŒ–å™¨è®¾ç½®
    seg_optimizer = torch.optim.SGD([
        {"params": shared_encoder.parameters(), "lr": 0.04},
        {"params": decoder.parameters(), "lr": 0.11},
        {"params": seg_net.parameters(), "lr": 0.012}
    ], momentum=0.9)

    # è®­ç»ƒå¾ªç¯
    for step in range(args.steps):
        # å‰å‘ä¼ æ’­
        output_seg = seg_net(decoder(shared_encoder(img_aug)))
        
        # æŸå¤±è®¡ç®—å’Œåå‘ä¼ æ’­
        loss.backward()
        seg_optimizer.step()

    # ä¿å­˜ç±»åˆ«ç‰¹å®šå‚æ•°
    torch.save({
        "decoder": decoder.state_dict(),
        "seg_net": seg_net.state_dict()
    }, f"saved_models/{category}_params.pth")
```

### 5. æ”¹è¿›çš„æµ‹è¯•æµç¨‹

```python
def test(args):
    # åˆå§‹åŒ–åˆ†ç±»ç½‘ç»œ
    classifier = FineTunedClassifier()
    
    # åˆå§‹åŒ–å…±äº«ç»„ä»¶
    shared_encoder = SharedEncoder()
    
    for img in test_imgs:
        # 1. åˆ†ç±»ç¡®å®šç±»åˆ«
        with torch.no_grad():
            pred = classifier(img)
            category = ALL_CATEGORY[torch.argmax(pred)]
        
        # 2. åŠ è½½å¯¹åº”ç±»åˆ«çš„æ¨¡å‹
        model = EnhancedDeSTSeg(category)
        
        # 3. æ‰§è¡Œå¼‚å¸¸æ£€æµ‹
        seg_map, de_st_map = model(img)
```

### æ–‡ä»¶ç»“æ„å»ºè®®

```
destseg/
â”œâ”€â”€ shared_components/
â”‚   â”œâ”€â”€ shared_encoder.pth
â”œâ”€â”€ category_components/
â”‚   â”œâ”€â”€ bottle/
â”‚   â”‚   â”œâ”€â”€ decoder.pth
â”‚   â”‚   â””â”€â”€ seg_net.pth
â”‚   â””â”€â”€ cable/
â”‚       â”œâ”€â”€ decoder.pth
â”‚       â””â”€â”€ seg_net.pth
â””â”€â”€ configs/
    â””â”€â”€ category_split.json
```

### å…³é”®æ”¹è¿›ç‚¹è¯´æ˜ï¼š

1.**å‚æ•°å…±äº«æœºåˆ¶**ï¼š

- å…±äº«ç¼–ç å™¨å‚æ•°å­˜å‚¨äº`shared_encoder.pth`
- ç±»åˆ«ç‰¹å®šå‚æ•°æŒ‰ç±»åˆ«åˆ†åˆ«å­˜å‚¨
- è®­ç»ƒæ—¶é€šè¿‡`torch.save`/`torch.load`å®ç°å‚æ•°åˆ†ç¦»

2.**åŠ¨æ€åŠ è½½æœºåˆ¶**ï¼š

```python
# åœ¨EnhancedDeSTSegåˆå§‹åŒ–æ—¶è‡ªåŠ¨åŠ è½½å¯¹åº”ç±»åˆ«çš„å‚æ•°
def __init__(self, category):
    self._load_category_params(category)
```

3.**åˆ†ç±»ç½‘ç»œé›†æˆ**ï¼š

```python
# åœ¨æµ‹è¯•æµç¨‹å¼€å§‹æ—¶å…ˆè¿›è¡Œåˆ†ç±»
pred = classifier(img)
category = ALL_CATEGORY[torch.argmax(pred)]
```

4.**è®­ç»ƒæµç¨‹ä¼˜åŒ–**ï¼š

```python
# æ¯ä¸ªç±»åˆ«è®­ç»ƒæ—¶åªæ›´æ–°ï¼š
# 1. å…±äº«ç¼–ç å™¨ï¼ˆæ‰€æœ‰ç±»åˆ«å…±ç”¨ï¼‰
# 2. å½“å‰ç±»åˆ«çš„decoderå’Œseg_net
optimizer = torch.optim.SGD([
    {"params": shared_encoder.parameters()},  # å…±äº«
    {"params": current_decoder.parameters()},  # å½“å‰ç±»åˆ«
    {"params": current_seg_net.parameters()}  # å½“å‰ç±»åˆ«
])
```

ä»¥ä¸Šå®ç°éœ€è¦é…åˆä»¥ä¸‹è°ƒæ•´ï¼š

1. ä¿®æ”¹æ•°æ®åŠ è½½é€»è¾‘ï¼Œç¡®ä¿ä¸åŒç±»åˆ«è®­ç»ƒæ—¶åŠ è½½å¯¹åº”å‚æ•°
2. å¢åŠ å‚æ•°ç®¡ç†å·¥å…·å‡½æ•°
3. å®Œå–„æ¨¡å‹ä¿å­˜/åŠ è½½çš„å¼‚å¸¸å¤„ç†
4. æ·»åŠ å¤šGPUè®­ç»ƒæ”¯æŒï¼ˆå¦‚éœ€ï¼‰

å»ºè®®åœ¨å®é™…éƒ¨ç½²æ—¶æ·»åŠ ï¼š

1. å‚æ•°ç‰ˆæœ¬æ§åˆ¶
2. è®­ç»ƒçŠ¶æ€ä¿å­˜/æ¢å¤
3. æ›´å®Œå–„çš„åˆ†ç±»å¤±è´¥å¤„ç†æœºåˆ¶
4. ç±»åˆ«é—´å‚æ•°å†²çªæ£€æµ‹æœºåˆ¶

è¿™ç§æ¶æ„å¯ä»¥è¾ƒå¥½åœ°å¹³è¡¡æ¨¡å‹æ€§èƒ½ä¸å‚æ•°æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒå¯¹ä¸åŒç±»åˆ«å¼‚å¸¸ç‰¹å¾çš„é’ˆå¯¹æ€§å¤„ç†èƒ½åŠ›ã€‚











promptï¼š

å¸®æˆ‘æŠŠå­¦ç”Ÿç½‘ç»œçš„SharedEncoderéƒ¨åˆ†ï¼ˆå…±äº«ç»„ä»¶ï¼‰æ¢ä¸TeacherNetä¸€æ ·çš„åœ¨imagenetä¸Šé¢„è®­ç»ƒå¥½çš„resnet18ç½‘ç»œæ¨¡å‹ï¼Œä¸”ä¿æŒåŸæ¥çš„SharedEncoderéƒ¨åˆ†çš„è¾“å…¥å’Œè¾“å‡ºä¸å˜ã€‚























































































































